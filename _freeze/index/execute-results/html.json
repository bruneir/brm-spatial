{
  "hash": "dce533cefd8db59ed466b7d9cec95cd7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Analysing spatial data using R\nsubtitle: Brunei R User Group Meetup ðŸ‡§ðŸ‡³\ndate: '9 March 2024'\nauthor:\n  - name: Haziq Jamil\n    orcid: 0000-0003-3298-1010\n    email: haziq.jamil@ubd.edu.bn\n    url: https://haziqj.ml\n    affiliation: Universiti Brunei Darussalam\n    degrees: PhD\n---\n\n\n### `https://bruneir.github.io/brm-spatial` {.unlisted}\n\n## Preliminaries\n\nWelcome to the first Brunei R User Group meetup!\n\n::: {layout=\"[ 65, 35 ]\"}\n::: {#first-column}\n<br>\n\n> The RUGS mission is to facilitate the person-to-person exchange of knowledge in small group settings on a global scale. ---R Consortium\n:::\n\n::: {#second-column}\n![](https://bruneir.github.io/bruneiR-Rlogo.jpg)\n\n``` r\n\"R\" |> \n  rug(\"b\", _, \"unei\")\n```\n:::\n:::\n\n<u>About us</u>\n\n-   A group of UBD-ians and R enthusiasts\n-   We want to create a community of R users in Brunei\n-   Champion the Open Source cause\n\nMore events to come this year. Stay tuned!\n\n### Expectations\n\n::: {.callout-warning title=\"Outcomes\"}\n-   This is a hands-on, live-coding, lecture-style \"workshop\".\n-   Expect to learn (or at the very least, see me do!)...\n    1.  What spatial data is and why it's important.\n    2.  What statistical analysis can be done with spatial data.\n    3.  How to perform spatial analysis using R.\n-   A basic understanding of R is assumed.\n:::\n\n![](inspirational_cat.jpg)\n\nFor some, maybe it will be a bit fast-paced (sorry in advanced!). \nAll the materials will be available online (see link on the right).\n\nI'm very happy to answer questions afterwards!\n\n### Getting started with R\n\nI'll just talk about these points briefly:\n\n- What's the difference between R and RStudio?\n- Quick run through RStudio's features\n- Set up a project\n- R Scripts vs Notebooks (`.qmd` or `.Rmd`)\n- Executing commands in R\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Try this out for yourself!\n\nN <- 100\nx <- runif(n = N, min = 0, max = 1)\nhead(x)  # Show the first 6 elements\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4974527 0.9538745 0.6624908 0.1469375 0.1052561 0.3865934\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nmean(x)  # Calculate the mean of this vector\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4868915\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nrun_x <- rep(NA, length(x))\nfor (i in seq_along(x)) {\n  run_x[i] <- sum(x[1:i])\n}\nhead(run_x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4974527 1.4513272 2.1138180 2.2607555 2.3660116 2.7526051\n```\n\n\n:::\n:::\n\n\n### List of packages\n\nThe power of R comes from its diverse range of user-contributed packages.\nTo install a package in R, we type `install.packages(\"package_name\")`.\nAs an example, try install the `{tidyverse}` package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\ninstall.packages(\"tidyverse\")\n```\n:::\n\n\nA bunch of things will happen on your screen that makes you look like a legit hacker.\n(It's normal! Unles... there are some errors in the installation process ðŸ˜…)\nOnce that's done, you will want to load the package to start using it.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(tidyverse)  # no need to use quotes\n```\n:::\n\n\nHere's a list of packages we will be using today. \nYou'll need to install all of them before we begin. \nIn RStudio, there will be a prompt (yellow line at the top of the source pane) for you to install all these packages with a single click.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntheme_set(theme_bw())  # set the theme\nlibrary(kernlab)       # for GPR\nlibrary(ggrepel)       # nice labels in plots\nlibrary(osrm)          # OSM route calculator\nlibrary(spdep)         # Moran's test and more\n```\n:::\n\n\nFurthermore, there are packages that are not yet on CRAN, but are available on GitHub. \nPlease install them using the `remotes` package.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nremotes::install_github(\"propertypricebn/bruneimap\")\n```\n:::\n\n\nOf course, don't forget to load it.\nFor more information, please check out the package's [GitHub page](https://github.com/propertypricebn/bruneimap).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(bruneimap)\n```\n:::\n\n\n## Introduction\n\nConsider the distribution of (smoothed out) house prices in Brunei^[Artificial data generated by predicted house prices using a GPR model with lat-long coordinates as inputs.].\nI think it is well accepted that the prices of houses in Brunei are not uniformly distributed across the country, but are determined by location.\nFigure 1 shows a faithful representation of house prices in Brunei, and we can clearly see a clustering effect.\nMany economists, realtors, and urban planners will undoubtedly tell you that there is some kind of \"neighbouring-effect\" at play here.\nHouse closer to each other tend to exhibit more similar properties.\n\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n\n```{.r .cell-code}\nload(\"data/artificial_hsp.RData\")\n\nforest_col <- adjustcolor(\"forestgreen\", alpha = 0.9)\nforest_col <- \"grey\"\n\nplot_hsp <- function(x) {\n  ggplot(x) +\n  geom_sf(aes(fill = y, col = \"\")) +\n  geom_sf(col = \"grey30\", fill = NA) +\n  scale_fill_viridis_c(\n    labels = scales::dollar, \n    name = \"Predicted price\", \n    alpha = 0.9, \n    na.value = forest_col\n  ) +\n  scale_colour_manual(values = NA) +              \n  guides(colour = guide_legend(\n    \"Forest reserve\", \n    override.aes = list(fill = forest_col, colour = forest_col)\n  ))\n}\n\np1 <- plot_hsp(hsp)\np2 <- \n  hsp |> \n  mutate(y = sample(y)) |> \n  plot_hsp()\n\np1\np2\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-hsp-spatial-1.png){#fig-hsp-spatial-1 fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/fig-hsp-spatial-2.png){#fig-hsp-spatial-2 fig-align='center' width=100%}\n:::\n:::\n\n\nWhen we perform statistical modelling and ignore the spatial component, effectively what we are assuming is that the prices of houses are independent of their location.\nUnder this assumption, Figure 2 is a valid representation of house prices in Brunei (uniformity of prices).\nThis is a very dangerous thing to do, especially when the spatial effect are non-ignorable. \nWe may get nonsensical results and inferences out of the resulting model.\n\nOf course, the degree to which this assumption is violated depends on the context and the problem at hand, as well as the scale of the data.\nFor the above-type problem where we have *area-level data*, one can use the Moran's I test of global heterogeneity to test for spatial autocorrelation.\nIt tests\n\n> | $H_0$: No spatial autocorrelation \n  | $H_1$: (Positive) Spatial autocorrelation present\n\nTo test this in R, we can use the `moran.test` function from the `{spdep}` package.\nThere are two key ingredients here, the actual data itself (house prices), but also the relationship between all the areas (neighbourhood structure).\nThe code is as follows.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prepare neighbourhood strucuture\nnb <- poly2nb(hsp, queen = FALSE)\nWlist <- nb2listw(nb, zero.policy = TRUE, style = \"B\")\n\n# Moran's test\nmoran.test(hsp$y, listw = Wlist, zero.policy = TRUE, na.action = na.omit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  hsp$y  \nweights: Wlist \nomitted: 6, 7, 11, 13, 20, 57, 70, 77, 107, 139, 146, 147, 167, 169, 171, 175, 176, 177, 182, 183, 185, 187, 189, 198, 209, 211, 217, 218, 227, 229, 231, 234, 249, 250, 252, 253, 260, 262, 263, 264, 270, 271, 273, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 291, 292, 299, 305, 311, 329, 353, 357, 362, 378, 379, 380, 384, 388, 402, 405, 407, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 438 \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 24.919, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.899352380      -0.002881844       0.001310926 \n```\n\n\n:::\n:::\n\n\n### Types of GIS data\n\nRoughly speaking, there are 4 types of GIS data.\n\n1.  **Points**\n    -   Having $(X, Y)$ coordinates (latitude, longitude, or projected coordinates, and are \"zero-dimensional\".\n    -   E.g. shopping malls, hospitals, outbreaks, etc.\n2.  **Lines**\n    -   A collection of points that form a path or a boundary. Has length.\n    -   E.g. roads, rivers, pipelines, etc.\n3.  **Polygons**\n    -   A closed area made up of line segments or curves.\n    -   E.g. countries, districts, buildings, etc.\n4.  **Raster**\n    -   Pixelated (or gridded) data where each pixel is associated with a geographical area and some measurement.\n    -   E.g. satellite images, elevation data, etc.\n\nThe first three are usually referred to as *vector data*. GIS data can be stored in various formats such as `.shp` or `.geojson`. The handling of GIS data (at least vector type data) is facilitated by the `{sf}` package [@pebesma2023spatial] which uses the *simple features* standard.\n\n::: callout-note\n*Simple features* refers to a formal standard (ISO 19125-1:2004) that describes how objects in the real world can be represented in computers, with emphasis on the spatial geometry of these objects.\n:::\n\nIt's helpful to think about the shape of this spatial data set. As an example, here's a random slice of 10 kampong-level population data for Brunei:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nleft_join(\n  kpg_sf, \n  bn_census2021, \n  by = join_by(id, kampong, mukim, district)\n) |>\n  select(\n    kampong, population, geometry\n  ) |>\n  slice_sample(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 10 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 114.2782 ymin: 4.395845 xmax: 115.0875 ymax: 4.998223\nGeodetic CRS:  WGS 84\n# A tibble: 10 Ã— 3\n   kampong          population                                          geometry\n   <chr>                 <dbl>                                     <POLYGON [Â°]>\n 1 Kg. Maraburong          457 ((114.777 4.831059, 114.777 4.830992, 114.777 4.â€¦\n 2 Kg. Pangalayan           NA ((114.2999 4.474793, 114.3013 4.474654, 114.3014â€¦\n 3 Kg. Ratan                57 ((114.4638 4.432706, 114.4641 4.432685, 114.4643â€¦\n 4 Kg. Bisut                NA ((114.5156 4.553508, 114.5154 4.553194, 114.5153â€¦\n 5 Kg. Labi Lama             4 ((114.4552 4.407087, 114.4559 4.406605, 114.4561â€¦\n 6 Kg. Serambangun         502 ((114.661 4.79441, 114.6611 4.793772, 114.6613 4â€¦\n 7 Kg. Kenua               114 ((115.0836 4.623055, 115.0837 4.622537, 115.0839â€¦\n 8 Kg. Ukong               346 ((114.6385 4.680959, 114.6401 4.680787, 114.6401â€¦\n 9 Kg. Belingos             22 ((115.0807 4.676201, 115.0799 4.674438, 115.0787â€¦\n10 Kg. Sungai Buloh       4351 ((115.0238 4.995128, 115.0238 4.995109, 115.0238â€¦\n```\n\n\n:::\n:::\n\n\nSpatial data analysis must have these two components:\n\n1.  The study variables (in the above example, this is population data).\n2.  GIS data regarding that study variable.\n\nIf we only have 1 without 2, then it really is just a regular data analysis (stating the obvious). Adding the GIS data is a process called \"geocoding\" the data points.\n\n::: callout-note\nIn R, geocoding using `{tidyverse}` can be achieved using the `dplyr::left_join()` or similar `xxx_join()` family of functions.\n:::\n\n## `(MULTI)POINT` data\n\nUsing the data from @jaafar2023data on the physicochemical characteristics and texture classification of soil in Bornean tropical heath forests affected by exotic Acacia mangium.\nThere are three datasets provided.\n\n1.  GIS data ([WGS84](https://en.wikipedia.org/wiki/World_Geodetic_System \"World Geodetic System\") coordinates) of all study plots.\n2.  Soil physicochemical property data. This contains details of soil physical, chemical, nutrient concentration of the three habits studied.\n3.  Soil texture classification. Provides details on the classification of the soil texture in the habitats studied.\n\nWe will first load the data sets in R.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## Load the data sets\nsoil_gps <- read_csv(\n  \"data/8389823/GPS - Revised.csv\", \n  # IMPORTANT!!! The csv file has latin1 encoding as opposed to UTF-8\n  locale = readr::locale(encoding = \"latin1\")\n)\n  \nsoil_physico <- read_csv(\"data/8389823/Soil physicochemical properties.csv\")\nsoil_texture <- read_csv(\"data/8389823/Soil texture classification.csv\")\n```\n:::\n\n\n### Clean up the point data\n\nLet's take a look at the point data set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nglimpse(soil_gps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 18\nColumns: 5\n$ Forest_type  <chr> \"Kerangas\", \"Kerangas\", \"Kerangas\", \"Kerangas\", \"Kerangasâ€¦\n$ Habitat_type <chr> \"Intact\", \"Intact\", \"Intact\", \"Intact\", \"Intact\", \"Intactâ€¦\n$ Plot_name    <chr> \"KU1\", \"KU2\", \"KU3\", \"KU4\", \"KU5\", \"KU6\", \"KI1\", \"KI2\", \"â€¦\n$ Latitude     <chr> \"4Â° 35' 53.40\\\"N\", \"4Â° 35' 38.37\\\"N\", \"4Â° 35' 53.89\\\"N\", â€¦\n$ Longitude    <chr> \"114Â° 30' 39.09\\\"E\", \"114Â° 31' 05.89\\\"E\", \"114Â° 30' 38.90â€¦\n```\n\n\n:::\n:::\n\n\nThe first three columns are essentially the identifiers of the plots (forest type, habitat type, and the unique identification code for the study plot). However, the latitude and longitude needs a bit of cleaning up, because it's currently in character format. This needs to be in a formal Degree Minute Second `DMS` class that R can understand. For this we will use the `sp::char2dms()` function.\n\nAs an example let's take a look at the first latitude.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nx <- soil_gps$Latitude[1]\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"4Â° 35' 53.40\\\"N\"\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\n# convert it using sp::char2dms() function\nx <- sp::char2dms(x, chd = \"Â°\")\nx\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4d35'53.4\"N\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nstr(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormal class 'DMS' [package \"sp\"] with 5 slots\n  ..@ WS : logi FALSE\n  ..@ deg: int 4\n  ..@ min: int 35\n  ..@ sec: num 53.4\n  ..@ NS : logi TRUE\n```\n\n\n:::\n:::\n\n\nThis is a special class that R understands as being a latitude from Earth. To convert it to decimal, we just do `as.numeric()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nas.numeric(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.598167\n```\n\n\n:::\n:::\n\n\nNow let's do this for all the values in the `soil_gps` data. We will use the `dplyr::mutate()` function in a pipeline.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsoil_gps <-\n  soil_gps |>\n  mutate(\n    Latitude = as.numeric(sp::char2dms(Latitude, chd = \"Â°\")),\n    Longitude = as.numeric(sp::char2dms(Longitude, chd = \"Â°\"))\n  )\nsoil_gps\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 18 Ã— 5\n   Forest_type Habitat_type Plot_name Latitude Longitude\n   <chr>       <chr>        <chr>        <dbl>     <dbl>\n 1 Kerangas    Intact       KU1           4.60      115.\n 2 Kerangas    Intact       KU2           4.59      115.\n 3 Kerangas    Intact       KU3           4.60      115.\n 4 Kerangas    Intact       KU4           4.63      114.\n 5 Kerangas    Intact       KU5           4.60      115.\n 6 Kerangas    Intact       KU6           4.60      115.\n 7 Kerangas    Invaded      KI1           4.59      115.\n 8 Kerangas    Invaded      KI2           4.59      115.\n 9 Kerangas    Invaded      KI3           4.59      115.\n10 Kerangas    Invaded      KI4           4.59      115.\n11 Kerangas    Invaded      KI5           4.59      115.\n12 Kerangas    Invaded      KI6           4.59      115.\n13 Kerangas    Plantation   AP1           4.59      115.\n14 Kerangas    Plantation   AP2           4.59      115.\n15 Kerangas    Plantation   AP3           4.59      115.\n16 Kerangas    Plantation   AP4           4.59      115.\n17 Kerangas    Plantation   AP5           4.59      115.\n18 Kerangas    Plantation   AP6           4.59      115.\n```\n\n\n:::\n:::\n\n\n### Preliminary plot of the data\n\nUsing the data contained in the `{bruneimap}` package, we can plot the study areas on a map of Brunei.\nUse either the `brn_sf`, `dis_sf`, `mkm_sf` or `kpg_sf` data sets.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(brn_sf) +\n  geom_sf() +\n  geom_point(data = soil_gps, aes(Longitude, Latitude)) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nWe can zoom in a bit... but we have to find out manually the correct bounding box.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(mkm_sf) +\n  geom_sf() +\n  geom_sf(data = dis_sf, fill = NA, col = \"black\", linewidth = 1) +\n  geom_point(data = soil_gps, aes(Longitude, Latitude)) +\n  geom_text_repel(\n    data = soil_gps,\n    aes(Longitude, Latitude, label = Plot_name),\n    box.padding = 0.5,\n    max.overlaps = 30\n  ) +\n  coord_sf(\n    xlim = c(114.4, 114.6),\n    ylim = c(4.5, 4.7)\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n### Merge with the study data\n\nLet's take a look at the data set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"false\"}\nglimpse(soil_physico)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 144\nColumns: 16\n$ Habitat_type              <chr> \"Intact\", \"Intact\", \"Intact\", \"Intact\", \"Intâ€¦\n$ Plot_name                 <chr> \"KU1\", \"KU1\", \"KU1\", \"KU1\", \"KU1\", \"KU1\", \"Kâ€¦\n$ Subplot_name              <chr> \"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"D\", \"D\", \"A\",â€¦\n$ Soil_depth                <chr> \"0-15\", \"30-50\", \"0-15\", \"30-50\", \"0-15\", \"3â€¦\n$ Nitrogen                  <dbl> 0.617, 0.188, 0.663, 0.200, 0.465, 0.255, 0.â€¦\n$ Phosphorus                <dbl> 0.248, 0.129, 0.259, 0.295, 0.172, 0.145, 0.â€¦\n$ Magnesium                 <dbl> 0.000, 0.045, 0.054, 0.035, 0.079, 0.043, 0.â€¦\n$ Calcium                   <dbl> 0.167, 0.187, 0.148, 0.113, 0.253, 0.229, 0.â€¦\n$ Potassium                 <dbl> 0.059, 0.037, 0.054, 0.022, 0.098, 0.033, 0.â€¦\n$ Exchangable_magnesium     <dbl> 0.009, 0.004, 0.007, 0.005, 0.029, 0.014, 0.â€¦\n$ Exchangable_calcium       <dbl> 0.010, 0.009, 0.008, 0.009, 0.109, 0.041, 0.â€¦\n$ Exchangable_potassium     <dbl> 0.101, 0.085, 0.092, 0.087, 0.101, 0.090, 0.â€¦\n$ Available_phosphorus      <dbl> 0.012, 0.012, 0.013, 0.012, 0.013, 0.014, 0.â€¦\n$ pH                        <dbl> 2.3, 2.7, 2.0, 2.0, 2.6, 2.5, 2.3, 2.1, 1.0,â€¦\n$ Gravimetric_water_content <dbl> 5.911, 3.560, 10.860, 5.082, 6.963, 4.549, 5â€¦\n$ Organic_matter            <dbl> 4.559, 1.399, 4.523, 2.309, 3.131, 2.209, 3.â€¦\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"false\"}\nglimpse(soil_texture)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 144\nColumns: 8\n$ Habitat_type           <chr> \"Intact\", \"Intact\", \"Intact\", \"Intact\", \"Intactâ€¦\n$ Plot_name              <chr> \"KU1\", \"KU1\", \"KU1\", \"KU1\", \"KU2\", \"KU2\", \"KU2\"â€¦\n$ Subplot_name           <chr> \"A\", \"B\", \"C\", \"D\", \"A\", \"B\", \"C\", \"D\", \"A\", \"Bâ€¦\n$ Soil_depth             <chr> \"0-15\", \"0-15\", \"0-15\", \"0-15\", \"0-15\", \"0-15\",â€¦\n$ Clay                   <dbl> 0.0, 0.0, 0.0, 0.0, 0.0, 2.5, 2.5, 2.5, 0.0, 2.â€¦\n$ Silt                   <dbl> 2.5, 0.0, 0.0, 2.5, 0.0, 0.0, 2.5, 2.5, 7.5, 7.â€¦\n$ Sand                   <dbl> 97.5, 100.0, 100.0, 97.5, 100.0, 97.5, 95.0, 95â€¦\n$ Texture_classification <chr> \"Sand\", \"Sand\", \"Sand\", \"Sand\", \"Sand\", \"Sand\",â€¦\n```\n\n\n:::\n:::\n\n\nThe `soil_physico` and `soil_texture` data sets contain the same columns, so we might as well merge them together. \nWe will use the `dplyr::left_join()` function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Actually I just want to merge these two together\nsoil_df <- left_join(\n  soil_physico,\n  soil_texture,\n  by = join_by(Habitat_type, Plot_name, Subplot_name, Soil_depth)\n)\nsoil_df\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 144 Ã— 20\n   Habitat_type Plot_name Subplot_name Soil_depth Nitrogen Phosphorus Magnesium\n   <chr>        <chr>     <chr>        <chr>         <dbl>      <dbl>     <dbl>\n 1 Intact       KU1       A            0-15          0.617      0.248     0    \n 2 Intact       KU1       A            30-50         0.188      0.129     0.045\n 3 Intact       KU1       B            0-15          0.663      0.259     0.054\n 4 Intact       KU1       B            30-50         0.2        0.295     0.035\n 5 Intact       KU1       C            0-15          0.465      0.172     0.079\n 6 Intact       KU1       C            30-50         0.255      0.145     0.043\n 7 Intact       KU1       D            0-15          0.285      0.225     0.052\n 8 Intact       KU1       D            30-50         0.057      0.207     0.031\n 9 Intact       KU2       A            0-15          0.37       0.135     0.038\n10 Intact       KU2       A            30-50         0.114      0.168     0.021\n# â„¹ 134 more rows\n# â„¹ 13 more variables: Calcium <dbl>, Potassium <dbl>,\n#   Exchangable_magnesium <dbl>, Exchangable_calcium <dbl>,\n#   Exchangable_potassium <dbl>, Available_phosphorus <dbl>, pH <dbl>,\n#   Gravimetric_water_content <dbl>, Organic_matter <dbl>, Clay <dbl>,\n#   Silt <dbl>, Sand <dbl>, Texture_classification <chr>\n```\n\n\n:::\n:::\n\n\nOnce we've done that, the `soil_df` data set (the study variables) is actually missing the spatial data. \nWe need to geocode it with the `soil_gps` data set.\nAgain, `dplyr::left_join()` to the rescue!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsoil_df <- left_join(\n  soil_df, \n  soil_gps,\n  by = join_by(Habitat_type, Plot_name)\n)\n```\n:::\n\n\nNow we're in a position to plot the study variables on the map.\nNote that there are only 18 plots in the `soil_gps` data set, and each plot has repeated measurements. \nThat means when we plot it, it will overlap and look like a single point. \nSo a good thing to do is to jitter the point so it's easier to see.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(kpg_sf) +\n  geom_sf(fill = NA) +\n  geom_jitter(\n    data = soil_df, \n    aes(Longitude, Latitude, col = Nitrogen, size = Nitrogen, \n        shape = Habitat_type),\n    width = 0.001, height = 0.001, alpha = 0.7\n  ) +\n  coord_sf(\n    xlim = c(114.46, 114.54),\n    ylim = c(4.58, 4.64)\n  ) +\n  scale_color_viridis_c() +\n  guides(size = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n### Predictive models\n\nAt this stage, we probably want to consult an expert in this field, and ask what variables are important for predicting the nitrogen content in the soil, so that we can build a *predictive model*.\nIn mathematics, a model is simply a relationship between variables, like so:\n$$\ny = f(x_1,x_2,\\dots,x_p) + \\epsilon\n$$\nwhere the $x_1,\\dots,x_p$ are the input variables, and $y$ is the output variable of interest (in this case, nitrogen concentrations).\nNo model can perfectly account for this relationship, so we add a term $\\epsilon$ which represents the error in the model.\nIdeally this should be as small as possible.\n\nSeveral models, ranging from classical statistical models to complex machine learning models, are possible:\n\n1. Linear regression model -- `lm()`\n2. Generalised additive models (GAM) [@wood2017generalized] -- `mgcv::gam()`\n3. Gaussian process regression (Kriging) -- `kernlab::gausspr()`\n4. Random forests -- `randomForest::randomForest()`\n5. Geographically weighted regression (GWR) -- `spgwr::gwr()`\n\nLet's focus on Gaussian process regression (because that's one that I know quite well).\nThe idea of GPR is to model the relationship between the input variables and the output variable as a multivariate Gaussian distribution:\n$$\nf(x) \\sim \\operatorname{N}\\big(0, K(x,x')\\big)\n$$\nwhere $K(x,x')$ is the covariance function, which measures the similarity between the input variables $x$ and $x'$.\nThe most common covariance function is the squared exponential function:\n$$\nK(x,x') = \\exp\\left(-\\frac{1}{2}\\sum_{i=1}^p (x_i - x'_i)^2\\right).\n$$\nLet $d$ represent the \"distance\" between two points. \nThen the squared exponential kernel becomes very small when this distance $d$ is large, and very large when $d$ is small.\nPut another way, since elements of the matrix $K$ represent co-variability, that means two points that are close together will behave similarly, and vice versa.\nThis is very much in line with Tobler's first law of geography: \"Everything is related to everything else, but near things are more related than distant things\".\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- seq(-4, 4, length = 100)\ny <- exp(-x^2)\ntibble(d = x, Kxx = y) |>\n  ggplot(aes(d, Kxx)) +\n  geom_line() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nGiven the assumed behaviour of our function $f(x)$, and what is observed from the data, we can then make predictions about the nitrogen content at unobserved locations.\nSkipping over a whole lot of mathematics, let's just fit this model in R.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Build a model to predict Nitrogen from all numeric variables. This is\n# definitely not theory based, so just want to show the code.\nsoil_df <-\n  soil_df |>\n  select(where(is.numeric)) \nmod <- gausspr(Nitrogen ~ ., data = soil_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nUsing automatic sigma estimation (sigest) for RBF or laplace kernel \n```\n\n\n:::\n\n```{.r .cell-code}\nmod\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGaussian Processes object of class \"gausspr\" \nProblem type: regression \n\nGaussian Radial Basis kernel function. \n Hyperparameter : sigma =  0.0746292376040134 \n\nNumber of training instances learned : 144 \nTrain error : 0.108538841 \n```\n\n\n:::\n:::\n\n\nHaving done that, we now want to prepare a prediction data frame.\nEssentially, we will rasterise the study area into a predefined grid.\nFor the other variables, we will just set them at their mean values.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nxr <- c(114.4, 114.6)\nxx <- seq(xr[1] - 0.01, xr[2] + 0.01, length = 100)\n\nyr <- c(4.5, 4.7)\nyy <- seq(yr[1] - 0.01, yr[2] + 0.01, length = 100)\n\nmean_X <- \n  soil_df |>\n  summarise(across(everything(), mean)) |>\n  select(-Longitude, -Latitude)\n\npred_df <-\n  expand_grid(\n    Longitude = xx,\n    Latitude = yy\n  ) |>\n  bind_cols(mean_X)\n\npred_df$ypred <- predict(mod, newdata = pred_df)\n\n# Additional step: filter points that are outside of the Brunei land area.\npred_sf <- \n  pred_df |>\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) |>\n  st_filter(y = brn_sf[1, ])\n\nggplot() +\n  geom_raster(\n    data = pred_sf,\n    aes(fill = ypred, geometry = geometry),\n    stat = \"sf_coordinates\",\n    alpha = 0.8\n  ) +\n  # geom_raster(data = pred_df, aes(Longitude, Latitude, fill = ypred),\n  #             alpha = 0.8) +\n  geom_sf(data = kpg_sf, fill = NA, inherit.aes = FALSE, col = \"black\") +\n  geom_sf(data = dis_sf, fill = NA, col = \"black\", linewidth = 1) +\n  geom_point(data = soil_gps, aes(Longitude, Latitude, \n                                  shape = Habitat_type)) +\n  geom_text_repel(\n    data = soil_gps,\n    aes(Longitude, Latitude, label = Plot_name),\n    box.padding = 0.5,\n    max.overlaps = 30\n  ) +\n  scale_fill_viridis_c() +\n  scale_colour_viridis_c() +\n  coord_sf(xlim = xr, ylim = yr)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n::: {.callout-warning}\nGarbage In Garbage Out! Modelling is as much an art as it is a science. Careful consideration needs to be made as to what is considered a predictor of a variable.\n:::\n\n\n<!-- ```{r} -->\n\n<!-- ggplot(kpg_sf) + -->\n\n<!--   geom_sf(aes(fill = mukim), col = \"gray50\") + -->\n\n<!--   geom_sf(data = mkm_sf, col = \"black\", lwd = 0.5, fill = NA) + -->\n\n<!--   geom_sf(data = filter(kpg_sf, is.na(mukim)), fill = \"gray70\", col = \"gray70\") + -->\n\n<!--   scale_fill_viridis_d(option = \"turbo\") + -->\n\n<!--   theme(legend.position = \"none\")  -->\n\n<!-- ``` -->\n\n## Line data (`(MULTI)LINESTRING`)\n\nFor this example, we'll play with the road network shape file obtained from OpenStreetMaps.\nThe data is in geojson format, so let's import that into R.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbrd <- \n  read_sf(\"data/hotosm_brn_roads_lines_geojson/hotosm_brn_roads_lines_geojson.geojson\") |>\n  sf::st_transform(4326)  # SET THE CRS!!! (WGS84)\nglimpse(brd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 25,570\nColumns: 15\n$ name       <chr> \"Simpang 393\", \"Simpang 405\", NA, NA, NA, NA, \"Lebuhraya Tuâ€¦\n$ `name:en`  <chr> NA, NA, NA, NA, NA, NA, \"Tutongâ€“Telisai Highway\", NA, NA, Nâ€¦\n$ highway    <chr> \"residential\", \"residential\", \"service\", \"residential\", \"trâ€¦\n$ surface    <chr> NA, NA, NA, NA, NA, \"asphalt\", \"asphalt\", NA, NA, NA, \"asphâ€¦\n$ smoothness <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦\n$ width      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦\n$ lanes      <chr> NA, NA, NA, NA, NA, \"1\", \"2\", NA, NA, NA, \"2\", NA, NA, NA, â€¦\n$ oneway     <chr> NA, NA, NA, NA, NA, \"yes\", \"yes\", NA, NA, NA, \"no\", \"yes\", â€¦\n$ bridge     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦\n$ layer      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦\n$ source     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦\n$ `name:ms`  <chr> NA, NA, NA, NA, NA, NA, \"Lebuhraya Tutongâ€“Telisai\", NA, NA,â€¦\n$ osm_id     <int> 386886618, 481030903, 512405939, 664532755, 442044892, 6651â€¦\n$ osm_type   <chr> \"ways_line\", \"ways_line\", \"ways_line\", \"ways_line\", \"ways_lâ€¦\n$ geometry   <LINESTRING [Â°]> LINESTRING (114.6236 4.7910..., LINESTRING (114.â€¦\n```\n\n\n:::\n:::\n\n\nThere are 25,570 features in this data set, which may be a bit too much.\nLet's try to focus on the major roads only.\nThis information seems to be contained in the `highway` column.\nWhat's in it?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntable(brd$highway)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     bridleway   construction       cycleway        footway  living_street \n             1             28             73            898             10 \n      motorway  motorway_link           path     pedestrian        primary \n           116            152            140             60            865 \n  primary_link    residential           road      secondary secondary_link \n           332           9023              1            446             79 \n       service          steps       tertiary  tertiary_link          track \n          9876             53            586             59            442 \n         trunk     trunk_link   unclassified \n           460            310           1560 \n```\n\n\n:::\n:::\n\n\nAccording to this [wiki](https://wiki.openstreetmap.org/wiki/OpenStreetMap_Carto/Lines), In OpenStreetMap, the major roads of a road network are sorted on an importance scale, from motorway to quaternary road.\n\n![](osm_roads.png)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbrd_mjr <- \n  brd |>\n  filter(highway %in% c(\"motorway\", \"trunk\", \"primary\", \"secondary\")) \nbrd_mjr\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 1887 features and 14 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 114.1906 ymin: 4.516642 xmax: 115.2021 ymax: 5.037115\nGeodetic CRS:  WGS 84\n# A tibble: 1,887 Ã— 15\n   name     `name:en` highway surface smoothness width lanes oneway bridge layer\n * <chr>    <chr>     <chr>   <chr>   <chr>      <chr> <chr> <chr>  <chr>  <chr>\n 1 Lebuhraâ€¦ Tutongâ€“Tâ€¦ trunk   asphalt <NA>       <NA>  2     yes    <NA>   <NA> \n 2 Lebuhraâ€¦ Tutongâ€“Tâ€¦ trunk   asphalt <NA>       <NA>  3     yes    <NA>   <NA> \n 3 Jalan Sâ€¦ <NA>      primary asphalt <NA>       <NA>  2     yes    yes    1    \n 4 Jalan Sâ€¦ <NA>      primary asphalt <NA>       <NA>  2     yes    <NA>   <NA> \n 5 Lebuh Râ€¦ Seriaâ€“Beâ€¦ trunk   asphalt <NA>       <NA>  2     yes    <NA>   <NA> \n 6 <NA>     <NA>      trunk   asphalt <NA>       <NA>  2     yes    <NA>   <NA> \n 7 <NA>     <NA>      primary asphalt <NA>       <NA>  1     yes    <NA>   <NA> \n 8 Lebuh Râ€¦ Seriaâ€“Beâ€¦ trunk   asphalt <NA>       <NA>  2     yes    yes    1    \n 9 <NA>     <NA>      primary asphalt <NA>       <NA>  2     yes    <NA>   <NA> \n10 Lebuhraâ€¦ Telisaiâ€“â€¦ trunk   asphalt <NA>       <NA>  2     yes    <NA>   <NA> \n# â„¹ 1,877 more rows\n# â„¹ 5 more variables: source <chr>, `name:ms` <chr>, osm_id <int>,\n#   osm_type <chr>, geometry <LINESTRING [Â°]>\n```\n\n\n:::\n:::\n\n\nAnd now a plot of these roads.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = brn_sf) +\n  geom_sf(data = brd_mjr, aes(col = highway), size = 0.5) +\n  # scale_colour_viridis_d(option = \"turbo\")\n  ggsci::scale_colour_npg()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nWith this, I asked ChatGPT what kind of spatial analyses can be done on this data set. \nIt said, when paired with appropriate data, we can do things like:\n\n1. **Network Connectivity Analysis**\n   - Assess reachability and identify disconnected road network components.\n\n2. **Accessibility and Service Area Analysis**\n   - Determine service areas and catchment areas for essential services.\n\n3. **Traffic Simulation and Management**\n   - Simulate traffic flow to identify bottlenecks and suggest optimal routing.\n\n4. **Environmental Impact Assessment**\n   - Estimate vehicular emissions and model noise pollution from roads.\n\n5. **Urban and Regional Planning**\n   - Examine land use compatibility and assess infrastructure development needs.\n\n6. **Safety Analysis**\n   - Identify accident hotspots and assess pedestrian safety.\n\n7. **Economic Analysis**\n   - Evaluate economic accessibility and the impact of road projects.\n\nLet's pick one of these: Calculate the distance between the centroid of several regions and the major hospital in the Belait district. \nThis analysis guides urban and healthcare planning by pinpointing areas with inadequate access to emergency services, enabling targeted infrastructure and service improvements. \n\n### Road networks in Belait region\n\nFirst we \"crop\" the road network to the Belait region.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbrd_belait <- \n  brd |>\n  st_intersection(filter(dis_sf, name == \"Belait\"))\n\nggplot(brd_belait) +\n  geom_sf() +\n  geom_sf(data = filter(dis_sf, name == \"Belait\"), fill = NA)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nIf we were to sample random points from the Belait polygon, we might get non-sensical areas like the extremely rural areas or forest reserves.\nSo the idea is to sample random points from the road network itself.\nFor this, we need a function that will get us a random point on the path itself.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_random_point <- function(linestring) {\n  coords <- st_coordinates(linestring)\n  samp_coord <- coords[sample(nrow(coords), 1), , drop = FALSE]\n  samp_coord[, 1:3]\n}\nget_random_point(brd_belait$geometry[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         X          Y         L1 \n114.241433   4.594193   1.000000 \n```\n\n\n:::\n:::\n\n\nOnce we have this function, we need to `map()` this function onto each of the linestrings in the `brd_belait` data set.\nThe resulting list of points is too large! \nSo we will just sample 100 points (you can experiment with this number).\n \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrandom_points <-\n  map(brd_belait$geometry, get_random_point) |>\n  bind_rows() |>\n  slice_sample(n = 100)\n```\n:::\n\n\nWhat we have now is a data frame of 100 random points on the road network in the Belait district.\nWe will use the `{osrm}` package to calculate the distance between these points and the Suri Seri Begawan Hospital in Kuala Belait.\nThe output will be three things: 1) The duration (minutes); 2) The distance (km); and 3) a `LINESTRING` object that represents the path to get to the hospital.\nUnfortunately the `osrmRoute()` function is not vectorised, i.e. we have to do it one-by-one for each of the 100 points.\nLuckily, we can just make a `for` loop and store the results in a list.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsuriseri <- c(114.198778, 4.583444)\n\nres <- list()\nfor (i in 1:100) {\n  res[[i]] <- osrmRoute(src = random_points[i, 1:2], dst = suriseri, overview = \"full\")\n}\nres <- \n  bind_rows(res) |>\n  as_tibble() |>\n  st_as_sf()\nres\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 100 features and 4 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 114.1735 ymin: 4.31172 xmax: 114.6695 ymax: 4.69715\nGeodetic CRS:  WGS 84\n# A tibble: 100 Ã— 5\n   src   dst   duration distance                                        geometry\n   <chr> <chr>    <dbl>    <dbl>                                <LINESTRING [Â°]>\n 1 1     dst       7.05     4.95 (114.2279 4.57929, 114.2286 4.57936, 114.2293 â€¦\n 2 1     dst      30.1     34.5  (114.4349 4.65194, 114.4349 4.65194, 114.435 4â€¦\n 3 1     dst      34.1     37.3  (114.4722 4.67361, 114.4722 4.67361, 114.4726 â€¦\n 4 1     dst       7.81     5.13 (114.2398 4.59042, 114.2398 4.59042, 114.2398 â€¦\n 5 1     dst       3.40     1.94 (114.2081 4.58047, 114.208 4.58063, 114.208 4.â€¦\n 6 1     dst       9.88     7.01 (114.2519 4.59031, 114.2512 4.59006, 114.2512 â€¦\n 7 1     dst      13.7     11.0  (114.2725 4.58835, 114.2707 4.58774, 114.2708 â€¦\n 8 1     dst      11.4      8.60 (114.2707 4.59975, 114.2702 4.59957, 114.2701 â€¦\n 9 1     dst       7.17     4.73 (114.2289 4.58423, 114.2296 4.58426, 114.2298 â€¦\n10 1     dst      12.5      9.17 (114.2751 4.6017, 114.2751 4.60168, 114.2751 4â€¦\n# â„¹ 90 more rows\n```\n\n\n:::\n:::\n\n\nSo with all that done, we can now plot the paths taken by the 100 random points to the hospital. \nThe map gives us an indication of which areas are underserved by the hospital, and can guide urban and healthcare planning by pinpointing areas with inadequate access to emergency services, enabling targeted infrastructure and service improvements.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(res) +\n  # geom_point(data = random_points, aes(x = X, y = Y), col = \"red\") +\n  geom_sf(data = filter(kpg_sf, district == \"Belait\"), fill = NA) +\n  geom_sf(aes(col = duration), linewidth = 1.2, alpha = 0.7) +\n  geom_point(x = suriseri[1], y = suriseri[2], col = \"red3\", pch = \"X\", \n             size = 3) +\n  scale_colour_viridis_c() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-32-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nImproving the analysis\n\n- Weight analysis by populous areas. Outcalls to hospitals can be modelled using a Poisson distribution with the population as the rate parameter.\n- Use a more sophisticated routing algorithm that accounts for traffic conditions and road quality (am vs pm, weekends vs weekdays, etc.).\n- Simpler to analyse at the kampong or mukim level? \n\n## Areal data (`(MULTI)POLYGONS`)\n\n::: {.callout-tip title=\"What we'll learn\"}\n-   Represent statistical data using colour mapping symbology (choropleth)\n-   Use `ggplot2::geom_label()` or `ggrepel::geom_label_repel()` to add labels to the map\n-   Using a binned colour scale, e.g. `ggplot2::geom_scale_fill_viridis_b()`\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbn_pop_sf <- \n  left_join(\n    kpg_sf, \n    bn_census2021, \n    by = join_by(id, kampong, mukim, district\n  ))\n\nkpg_labels_sf <-\n  bn_pop_sf |>\n  arrange(desc(population)) |>\n  slice_head(n = 10)\n\nbn_pop_sf |>\n  # filter(population > 50) |>\n  ggplot() +\n  geom_sf(aes(fill = population), col = NA, alpha = 0.8) +\n  geom_sf(data = kpg_sf, fill = NA, col = \"black\") +\n  ggrepel::geom_label_repel(\n    data = kpg_labels_sf,\n    aes(label = kampong, geometry = geometry),\n    stat = \"sf_coordinates\",\n    inherit.aes = FALSE,\n    box.padding = 1,\n    size = 2,\n    max.overlaps = Inf\n  ) +\n  scale_fill_viridis_b(\n    name = \"Population\",\n    na.value = NA,\n    labels = scales::comma,\n    breaks = c(0, 50, 100, 1000, 5000, 10000, 15000)\n    # limits = c(0, 12000)\n  ) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){fig-align='center' width=100%}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}